{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9b88a5109dab>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-1-9b88a5109dab>:44: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "0     0.66878474     0.6776694\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    new_saver = tf.train.import_meta_graph('model_save.ckpt.meta')\n",
    "#    new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "\n",
    "x_data = np.loadtxt('./inputData.txt', delimiter = ',', unpack = True, dtype = 'float32')\n",
    "x_data = np.transpose(x_data)\n",
    "y_data = np.loadtxt('./Label.txt', delimiter = ',', unpack = True, dtype = 'float32')\n",
    "y_data = np.transpose(y_data)\n",
    "\n",
    "idx_shuffle = np.random.permutation(len(x_data))\n",
    "x_data = x_data[idx_shuffle]\n",
    "y_data = y_data[idx_shuffle]\n",
    "\n",
    "# Features and Labels\n",
    "X = tf.placeholder(tf.float32) # 1 x 7*3, (x, y, z)\n",
    "Y = tf.placeholder(tf.float32) # 1 x 2, softmax \n",
    "\n",
    "# Network\n",
    "w1 = tf.Variable(tf.random_normal([21, 128], stddev = .1))\n",
    "b1 = tf.Variable(tf.zeros([128]))\n",
    "\n",
    "L1 = tf.add(tf.matmul(X, w1), b1)\n",
    "L1_act = tf.nn.relu(L1)\n",
    "L1_do = tf.nn.dropout(L1_act, keep_prob = 0.7)\n",
    "                 \n",
    "w2 = tf.Variable(tf.random_normal([128, 128], stddev = .1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "\n",
    "L2 = tf.add(tf.matmul(L1_do, w2), b2)\n",
    "L2_act = tf.nn.relu(L2)\n",
    "L2_do = tf.nn.dropout(L2_act, keep_prob = 0.7)\n",
    "      \n",
    "w3 = tf.Variable(tf.random_normal([128, 2], stddev = .1))\n",
    "b3 = tf.Variable(tf.zeros([2]))\n",
    "         \n",
    "m = tf.add(tf.matmul(L2_do, w3), b3)\n",
    "model = tf.nn.softmax(m)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = model))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "\n",
    "save_file = './train_model.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for (step) in range(10001):\n",
    "        for (epoch) in range(36):\n",
    "            s = 100 * epoch\n",
    "            e = 100 * (epoch + 1)\n",
    "            sess.run(optimizer, feed_dict = {X:x_data[s:e], Y:y_data[s:e]})\n",
    "        \n",
    "        if (step) % 100 == 0:\n",
    "            c = sess.run(cost, feed_dict = {X:x_data[0:3600], Y:y_data[0:3600]})\n",
    "            c_test = sess.run(cost, feed_dict = {X:x_data[3600:], Y:y_data[3600:]})\n",
    "            #l1 = sess.run(model, feed_dict =  {X:x_data[0:10]}) \n",
    "            print(step, \"   \", c, \"   \", c_test)\n",
    "            #print(l1)\n",
    "\n",
    "        #tmp = 0.0\n",
    "        #count = 0\n",
    "\n",
    "        #if (step) % 100 == 0:\n",
    "        #    cost_test = sess.run(cost, feed_dict = {X:x_data[750:], Y:y_data[750:]})\n",
    "        #    if (tmp < cost_test):\n",
    "        #        count += 1\n",
    "        #        tmp = cost_test\n",
    "        #    else :\n",
    "        #        count = 0\n",
    "\n",
    "        #if (count > 10):\n",
    "        #    c = sess.run(cost, feed_dict = {X:x_data[0:750], Y:y_data[0:750]})\n",
    "        #    c_test = sess.run(cost, feed_dict = {X:x_data[750:], Y:y_data[750:]})\n",
    "        #    print(step, \"   \", c, \"   \", c_test)\n",
    "        #    break\n",
    "\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict = {X:x_data, Y:y_data}))\n",
    "    \n",
    "    print(sess.run(w1))\n",
    "    \n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
